{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"quicue-kg","text":"<p>CUE-native knowledge graph framework for tracking architectural decisions, patterns, insights, and rejected approaches \u2014 with compile-time validation.</p>"},{"location":"#why","title":"Why","text":"<p>Projects accumulate knowledge that lives outside source code: why a technology was chosen, what approaches failed, which patterns recur. This knowledge typically scatters across wikis, chat logs, and individual memory. When it's lost, teams re-explore failed paths and make decisions without context.</p> <p>quicue-kg stores this knowledge as typed CUE data in a <code>.kg/</code> directory alongside your code. CUE's type system enforces structure \u2014 every rejected approach must record an alternative, every insight must cite evidence. Validation is <code>cue vet .kg/</code>. No database, no server.</p> <p>Who this is for: Development teams who want queryable, validated project knowledge that lives in version control.</p>"},{"location":"#quick-start","title":"Quick start","text":"<pre><code># Initialize a knowledge graph in your project\nkg init\n\n# Record a decision\nkg add decision\n# Edit the generated file, then validate\nkg vet\n\n# See what you've recorded\nkg index --summary\n</code></pre> <p>A minimal <code>.kg/</code> looks like this:</p> <pre><code>package kg\n\nimport \"quicue.ca/kg/core@v0\"\n\ndecisions: {\n    \"ADR-001\": core.#Decision &amp; {\n        id:           \"ADR-001\"\n        title:        \"Use PostgreSQL for persistence\"\n        status:       \"accepted\"\n        date:         \"2026-01-15\"\n        context:      \"Need ACID transactions and JSONB support.\"\n        decision:     \"Use PostgreSQL 16 with JSONB columns for semi-structured data.\"\n        rationale:    \"Mature ecosystem, strong JSONB performance, team expertise.\"\n        consequences: [\"All persistence goes through PostgreSQL\", \"No separate document store needed\"]\n    }\n}\n</code></pre> <p>CUE validates this at compile time: missing fields, invalid status values, and malformed IDs are all caught before commit.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>module: \"quicue.ca/kg@v0\"\n</code></pre> <p>Via GHCR (available now): <pre><code>export CUE_REGISTRY='quicue.ca=ghcr.io/quicue/cue-modules,registry.cue.works'\ncue mod tidy\n</code></pre></p> <p>Via local symlink (development): <pre><code>mkdir -p cue.mod/pkg/quicue.ca/kg\nln -s /path/to/quicue-kg/* cue.mod/pkg/quicue.ca/kg/\n</code></pre></p>"},{"location":"#what-makes-this-different","title":"What makes this different","text":"<p>CUE's type system gives properties that are hard to get from traditional knowledge management:</p> <ol> <li> <p>Knowledge conflicts are type errors. If two teams assert contradictory facts about the same decision, CUE unification fails at build time \u2014 not silently at read time.</p> </li> <li> <p>Federation without infrastructure. Merging knowledge across projects is a CUE import, not a service call. <code>cue vet</code> catches conflicts. No shared database needed.</p> </li> <li> <p>Progressive refinement. CUE's type lattice only narrows, never broadens. A field constrained to <code>\"high\" | \"medium\" | \"low\"</code> can't silently accept <code>\"maybe\"</code>. Evidence accumulates; it can't disappear.</p> </li> <li> <p>Schema evolution as a quality ratchet. Adding a required field to <code>#Decision</code> makes every existing entry without it a validation error. The schema enforces improvement.</p> </li> <li> <p>Computed indexes. Summary views (<code>by_status</code>, <code>by_confidence</code>) are CUE comprehensions over the data. They're always in sync because they're derived, never maintained.</p> </li> </ol>"},{"location":"#types","title":"Types","text":""},{"location":"#core-core","title":"Core (<code>core/</code>)","text":"Type ID Pattern Purpose <code>#Decision</code> <code>ADR-NNN</code> Architecture decisions with mandatory rationale and consequences <code>#Pattern</code> \u2014 Reusable problem/solution pairs with cross-project tracking <code>#Insight</code> <code>INSIGHT-NNN</code> Validated discoveries with mandatory evidence and confidence level <code>#Rejected</code> <code>REJ-NNN</code> Failed approaches \u2014 must record what to do instead"},{"location":"#extensions-ext","title":"Extensions (<code>ext/</code>)","text":"Type Purpose <code>#Derivation</code> Data pipeline audit trails tracking how outputs relate to source data <code>#Workspace</code> Multi-repo topology mapping <code>#Context</code> Project identity and self-description"},{"location":"#aggregation-aggregate","title":"Aggregation (<code>aggregate/</code>)","text":"Type Purpose <code>#KGIndex</code> Computed summary, by_status, by_confidence views <code>#KGLint</code> Structural quality checks <code>#Provenance</code> PROV-O projection (decisions as provenance activities) <code>#DatasetEntry</code> DCAT projection (project as cataloged dataset) <code>#FederatedCatalog</code> DCAT catalog for federation results <code>#Annotations</code> Web Annotation projection (insights and rejected as annotations) <code>#Prolog</code> Prolog facts + inference rules for logic programming <code>#Datalog</code> Souffl\u00e9-compatible Datalog (guaranteed termination) <code>#NTriples</code> N-Triples \u2014 one triple per line, greppable RDF <code>#Turtle</code> Turtle \u2014 human-readable prefixed RDF <code>#SKOSTaxonomy</code> SKOS concept scheme from pattern categories"},{"location":"#linked-data-logic-projections","title":"Linked Data &amp; Logic Projections","text":"<p>The knowledge graph exports to W3C vocabularies and logic programming formats via CUE comprehensions. These projections make your knowledge graph interoperable with linked data tools, triplestores, and logic engines without replacing CUE as the source of truth.</p>"},{"location":"#rdf-semantic-web","title":"RDF &amp; Semantic Web","text":"Projection Standard Use case Export expression Provenance PROV-O Decision audit trails <code>_provenance.graph</code> Catalog DCAT Data catalog registration <code>_catalog.dataset</code> Annotations Web Annotation Insight/rejected as annotations <code>_annotations.graph</code> N-Triples RDF 1.1 Bulk triplestore loading, grep/sort/diff <code>_ntriples.triples</code> Turtle RDF 1.1 Human-readable RDF, SPARQL endpoint import <code>_turtle.document</code> SKOS SKOS Pattern taxonomy as browsable concept scheme <code>_taxonomy.graph</code>"},{"location":"#logic-programming","title":"Logic Programming","text":"Projection Runtime Use case Export expression Prolog SWI-Prolog Inference rules, transitive provenance queries <code>_prolog.program</code> Datalog Souffl\u00e9 Guaranteed-terminating queries at scale <code>_datalog.program</code> <pre><code># Export decision audit trail as PROV-O JSON-LD\ncue export .kg/ -e _provenance.graph --out json\n\n# Register project in a data catalog\ncue export .kg/ -e _catalog.dataset --out json\n\n# Greppable RDF for unix pipelines\ncue export .kg/ -e _ntriples.triples --out text\n\n# Human-readable RDF for SPARQL endpoints\ncue export .kg/ -e _turtle.document --out text\n\n# Pattern taxonomy as SKOS JSON-LD\ncue export .kg/ -e _taxonomy.graph --out json\n\n# Logic programming (Prolog facts + inference rules)\ncue export .kg/ -e _prolog.program --out text\n</code></pre>"},{"location":"#cli","title":"CLI","text":"<pre><code>Usage: kg &lt;command&gt; [args...]\n\nCommands:\n  init              Scaffold .kg/ directory with imports\n  add &lt;type&gt;        Create new entry (decision|pattern|insight|rejected)\n  vet               Validate .kg/ content\n  index [--full]    Export aggregated index as JSON\n  query &lt;expr&gt;      Query via CUE expression\n  lint              Knowledge quality checks\n  settle            Check for conflicts, coverage gaps, referential integrity\n  diff [ref]        Semantic changelog since git ref\n  link &lt;a&gt; &lt;b&gt;      Cross-reference two entries\n  graph [--dot]     Export relationships as JSON or DOT\n  fed &lt;dirs...&gt;     Federate multiple .kg/ directories\n</code></pre>"},{"location":"#specification","title":"Specification","text":"<p>The full specification (directory layout, type constraints, aggregation semantics, federation protocol) is published at quicue.github.io/quicue-kg/spec.html.</p> <p>JSON-LD vocabulary context: quicue.github.io/quicue-kg/context.jsonld</p>"},{"location":"#development","title":"Development","text":"<pre><code>make all          # Run all checks\nmake e2e          # End-to-end tests (schemas, exports, CLI, cross-repo)\nmake validate     # Validate schemas only\nmake test-valid   # Run valid test instances\nmake test-invalid # Confirm invalid instances are rejected\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"semantic-web/","title":"Semantic Web &amp; Logic Projections","text":"<p>quicue-kg exports knowledge graph data to RDF, SKOS, and logic programming formats. This page explains the data model, available formats, and when to use each one.</p>"},{"location":"semantic-web/#rdf-in-60-seconds","title":"RDF in 60 seconds","text":"<p>RDF (Resource Description Framework) stores data as triples: subject-predicate-object statements.</p> <pre><code>&lt;kg:ADR-001&gt;  &lt;rdf:type&gt;        &lt;kg:Decision&gt; .\n&lt;kg:ADR-001&gt;  &lt;rdfs:label&gt;      \"Use PostgreSQL\" .\n&lt;kg:ADR-001&gt;  &lt;prov:startedAt&gt;  \"2026-01-15\" .\n</code></pre> <p>Every fact is one triple. Triples compose \u2014 you can merge two RDF datasets by concatenating their triples. Subjects and predicates are IRIs (URIs); objects are IRIs or literal values. That's the entire model.</p> <p>The advantage: any tool that speaks RDF can query your knowledge graph. SPARQL endpoints, Oxigraph, Jena, rdflib \u2014 they all consume this format directly.</p>"},{"location":"semantic-web/#projection-architecture","title":"Projection architecture","text":"<p>All projections live in <code>kg/aggregate/</code> and follow the same pattern:</p> <pre><code>#SomeProjection: {\n    index: #KGIndex          // Input: the computed index\n    graph: { ... }            // Output: structured data\n    summary: { ... }          // Metadata: counts, stats\n}\n</code></pre> <p>CUE comprehensions iterate over the index and emit structured output. The projections are one-way: CUE is the source of truth, external formats are interoperability surfaces. You never edit the RDF \u2014 you edit the <code>.kg/</code> CUE files and re-export.</p>"},{"location":"semantic-web/#format-catalog","title":"Format catalog","text":""},{"location":"semantic-web/#rdf-serializations","title":"RDF serializations","text":"<p>These three formats express the same RDF data model in different wire formats:</p> Format File Type Best for N-Triples <code>ntriples.cue</code> <code>#NTriples</code> <code>grep</code>, <code>sort</code>, <code>diff</code>, bulk loading Turtle <code>turtle.cue</code> <code>#Turtle</code> Human reading, SPARQL endpoint import JSON-LD <code>provenance.cue</code> <code>#Provenance</code> Web APIs, browser consumption <p>N-Triples is the simplest: one triple per line, fully expanded IRIs, no prefixes. Perfect for unix pipelines:</p> <pre><code># Export and grep for all provenance activities\ncue export .kg/ -e _ntriples.triples --out text | grep 'prov#Activity'\n\n# Count triples by predicate\ncue export .kg/ -e _ntriples.triples --out text | awk '{print $2}' | sort | uniq -c | sort -rn\n</code></pre> <p>Turtle adds prefix declarations and groups triples by subject. Produces the same data as N-Triples but readable:</p> <pre><code>@prefix kg: &lt;https://quicue.ca/kg#&gt; .\n@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .\n\nkg:ADR-001 a kg:Decision, prov:Activity ;\n    rdfs:label \"Use PostgreSQL\" ;\n    prov:startedAtTime \"2026-01-15\"^^xsd:date .\n</code></pre> <pre><code>cue export .kg/ -e _turtle.document --out text\n</code></pre> <p>JSON-LD is JSON with <code>@context</code> mapping keys to IRIs. The PROV-O, DCAT, and Web Annotation projections all emit JSON-LD:</p> <pre><code>cue export .kg/ -e _provenance.graph --out json\ncue export .kg/ -e _catalog.dataset --out json\ncue export .kg/ -e _annotations.graph --out json\n</code></pre>"},{"location":"semantic-web/#semantic-vocabularies","title":"Semantic vocabularies","text":"<p>These projections add vocabulary-specific semantics on top of the raw data:</p> Projection Vocabulary Type Purpose PROV-O W3C Provenance <code>#Provenance</code> Decision audit trails, provenance chains DCAT Data Catalog <code>#DatasetEntry</code> Register projects in data catalogs Web Annotation W3C Annotation <code>#Annotations</code> Insights/rejected as scholarly annotations SKOS Simple Knowledge Org <code>#SKOSTaxonomy</code> Pattern categories as browsable taxonomy <p>SKOS is particularly useful for navigating patterns. It maps pattern categories to <code>skos:Concept</code> top concepts and individual patterns to narrower concepts within them:</p> <pre><code># JSON-LD concept scheme\ncue export .kg/ -e _taxonomy.graph --out json\n\n# Turtle for import into existing SKOS taxonomies\ncue export .kg/ -e _taxonomy.turtle --out text\n</code></pre>"},{"location":"semantic-web/#logic-programming","title":"Logic programming","text":"<p>These projections export facts + inference rules, not graph data. They make knowledge computable:</p> Projection Runtime Type Terminates? Prolog SWI-Prolog <code>#Prolog</code> No (Turing-complete) Datalog Souffl\u00e9 <code>#Datalog</code> Yes (guaranteed) <p>Both include 6 inference rules:</p> <ul> <li><code>contributed(Source, Deriv)</code> \u2014 transitive provenance (what sources fed into a derivation?)</li> <li><code>trust(Proto, Level)</code> \u2014 trust levels from protocol authority ranks</li> <li><code>most_authoritative(System, Proto)</code> \u2014 best protocol per system</li> <li><code>shared_pattern(P, Proj1, Proj2)</code> \u2014 patterns used across multiple projects</li> <li><code>active_decision(Id)</code> \u2014 accepted decisions</li> <li><code>actionable(Id)</code> \u2014 high-confidence insights</li> </ul> <pre><code># Export Prolog program\ncue export .kg/ -e _prolog.program --out text &gt; kb.pl\n\n# Query: which patterns are shared between projects?\nswipl -l kb.pl -g \"shared_pattern(P, A, B), format('~w shared by ~w and ~w~n', [P, A, B]), fail.\"\n\n# Export Datalog (guaranteed termination, compiles to C++)\ncue export .kg/ -e _datalog.program --out text &gt; kb.dl\nsouffle kb.dl\n</code></pre> <p>When to use Prolog vs Datalog: Use Prolog when you need recursive queries, negation-as-failure, or interactive exploration. Use Datalog when you need guaranteed termination (e.g., automated CI checks) or when evaluating over large datasets (Souffl\u00e9 compiles to native code).</p>"},{"location":"semantic-web/#choosing-a-format","title":"Choosing a format","text":"I want to... Use Load into a triplestore (Oxigraph, Jena) Turtle or N-Triples Process with unix tools (grep, sort, diff) N-Triples Serve from a web API JSON-LD (PROV-O, DCAT, or Annotations) Browse patterns as a taxonomy SKOS Query provenance chains Prolog or Datalog Run automated checks in CI Datalog (always terminates) Register in a data catalog DCAT Human-readable audit trail Turtle or PROV-O JSON-LD"},{"location":"semantic-web/#namespace","title":"Namespace","text":"<p>All projections use the <code>kg:</code> namespace prefix, which resolves to <code>https://quicue.ca/kg#</code>. The full JSON-LD context is defined in <code>vocab/context.cue</code> and published at <code>kg.quicue.ca/context.jsonld</code>.</p> <p>Standard prefixes used across projections:</p> Prefix IRI Vocabulary <code>kg:</code> <code>https://quicue.ca/kg#</code> quicue-kg types <code>prov:</code> <code>http://www.w3.org/ns/prov#</code> W3C Provenance <code>dcat:</code> <code>http://www.w3.org/ns/dcat#</code> Data Catalog <code>oa:</code> <code>http://www.w3.org/ns/oa#</code> Web Annotation <code>skos:</code> <code>http://www.w3.org/2004/02/skos/core#</code> Knowledge Organization <code>dcterms:</code> <code>http://purl.org/dc/terms/</code> Dublin Core Terms <code>rdfs:</code> <code>http://www.w3.org/2000/01/rdf-schema#</code> RDF Schema <code>rdf:</code> <code>http://www.w3.org/1999/02/22-rdf-syntax-ns#</code> RDF Syntax"},{"location":"specification/","title":"Specification","text":"<p>The full quicue-kg specification covers directory layout, type constraints, aggregation semantics, W3C projection mappings, and the federation protocol.</p> <p>Read the specification \u2192</p> <p>The specification is a W3C-style ReSpec document covering:</p> <ul> <li>Core types \u2014 <code>#Decision</code>, <code>#Pattern</code>, <code>#Insight</code>, <code>#Rejected</code> with validation rules</li> <li>Extension types \u2014 <code>#Derivation</code>, <code>#Workspace</code>, <code>#Context</code>, <code>#SourceFile</code>, <code>#CollectionProtocol</code>, <code>#PipelineRun</code></li> <li>Aggregation \u2014 <code>#KGIndex</code> computed views, <code>#KGLint</code> quality checks</li> <li>W3C projections \u2014 PROV-O, Web Annotation, DCAT, N-Triples, Turtle, SKOS, Prolog, Datalog</li> <li>Federation protocol \u2014 Cross-project discovery, merge semantics, conflict detection</li> <li>JSON-LD context \u2014 Namespace mappings and RDFS class hierarchy</li> </ul>"},{"location":"specification/#json-ld-context","title":"JSON-LD Context","text":"<p>The <code>kg:</code> namespace resolves to <code>https://quicue.ca/kg#</code>. The vocabulary context is available at:</p> <ul> <li>Machine-readable: context.jsonld</li> <li>Source: <code>vocab/context.cue</code> in the repository</li> </ul>"}]}